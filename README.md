# Enron Email Analytics (ETL + Analysis)

ETL pipeline to load raw email messages from a CSV (second column as `message`) into SQLite,
clean display names (including removing legacy Exchange DNs), parse timestamps to UTC, and
provide a quick analysis starter (daily trends, top senders, keyword hits).

## Features

- Reads only the **2nd column** of the CSV (ignores the first) as raw RFC‑822 email text.
- Parses `From/To/Cc/Bcc`, decodes/cleans display names:
  - Removes Exchange legacy DN blobs like `</O=ENRON/OU=.../CN=...>` or `&lt;...&gt;`
  - Normalizes `Surname, Name` → `Name Surname`
  - Derives from email local part if no name exists
- Parses `Date` to **UTC** + `year/month/day/hour` fields.
- Ensures `message_id` with fallback to `body_sha256` for dedupe.
- Schema for `emails`, `persons`, `domains`, `email_recipients`.
- Basic analysis script: daily volume, top senders, keyword hits.

## Quickstart

### 1) Python environment

```bash
python -m venv .venv
# Windows PowerShell:
. .venv/Scripts/Activate.ps1
# macOS/Linux:
source .venv/bin/activate

pip install -r requirements.txt
```

### 2) Add your data & configure

- Put your CSV at `data/raw/emails.csv` (or any name).
- Edit `etl/config.py` → set `CSV_PATH` to your CSV file and `CSV_HAS_HEADER` accordingly.

### 3) Run ETL

```bash
python -m etl.etl
```

This creates/overwrites the SQLite DB at `db/enron.db`.

### 4) Run analysis

```bash
python analysis/analysis_starter.py
```

### 5) (Optional) Create convenience view

```bash
sqlite3 db/enron.db < sql/views.sql
```

## Repository layout

```
enron-email-analytics/
├─ README.md
├─ LICENSE
├─ .gitignore
├─ requirements.txt
├─ etl/
│  ├─ __init__.py
│  ├─ etl.py
│  └─ config.py
├─ sql/
│  ├─ schema.sql
│  ├─ sanity_checks.sql
│  └─ views.sql
├─ analysis/
│  └─ analysis_starter.py
├─ data/
│  └─ raw/               # place CSVs here (ignored by git)
├─ db/
│  └─ enron.db           # generated by ETL (ignored by git)
└─ .github/
   └─ workflows/
      └─ ci.yml
```

## Notes

- If your CSV has **no header**, set `CSV_HAS_HEADER = False` in `etl/config.py`.
- If your CSV delimiter isn’t a comma, the ETL **auto-detects** it with `engine="python", sep=None`.
- Large datasets: adjust `CHUNK_SIZE` in `etl/config.py`.

## License

MIT — see `LICENSE`.
